---
title: " Volvo-bilar: EDA och Regressionsmodell"
author: "Zakariyae Mokhtari"
output: html_document
---



##  Inledning

Den h√§r rapporten utforskar f√∂rs√§ljningspriser f√∂r begagnade Volvo-bilar fr√•n Blocket. Syftet √§r att kombinera **Exploratory Data Analysis (EDA)** med **prediktiv modellering** f√∂r att identifiera de faktorer som p√•verkar priset mest, samt skapa tillf√∂rlitliga modeller f√∂r att f√∂ruts√§ga priser.

##  Importera och f√∂rbehandla data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(scales)
library(caret)
library(lmtest)
library(car)
```

```{r l√§s-data}
url <- "https://github.com/siffror/Regressionsmodellering_R_Bilannonser/raw/main/R_Volvo_data_bilar.xlsx"
temp <- tempfile(fileext = ".xlsx")
download.file(url, temp, mode = "wb")
data <- read_excel(temp)
```



##  EDA: Visualisering och sammanfattning

```{r}
str(data)
summary(data)
colSums(is.na(data))
```

###  Struktur och transformation

```{r}
colnames(data) <- make.names(colnames(data)) # Kolumnnamn g√∂rs till giltiga R-namn
data <- data %>% 
  select(-starts_with("...")) %>% #tomma kolumner tas bort  
  mutate(
    F√∂rs√§ljningspris = as.numeric(gsub("[^0-9]", "", F√∂rs√§ljningspris)), 
    Miltal = as.numeric(gsub("[^0-9]", "", Miltal)),
    H√§stkrafter = as.numeric(gsub("[^0-9]", "", H√§stkrafter)),
    Motorstorlek = as.numeric(gsub("[^0-9]", "", Motorstorlek)),
    Br√§nsle = str_to_title(as.character(Br√§nsle)) %>% as.factor(), # G√∂r om br√§nsle till faktor kategorisk variabel
    V√§xell√•da = as.factor(V√§xell√•da)
  ) # konvertera kolumner till r√§tt datatyper
```

```{r}
ggplot(data, aes(x = F√∂rs√§ljningspris)) +
  geom_histogram(binwidth = 25000, fill = "steelblue", color = "white") +
  scale_x_continuous(labels = comma) +
  labs(title = "F√∂rdelning av f√∂rs√§ljningspris", x = "Pris (kr)", y = "Antal bilar")
```
```{r}

library(plotly)

plot_ly(data = data, x = ~Miltal, y = ~`F√∂rs√§ljningspris`, type = "scatter", mode = "markers") %>%
  layout(title = "F√∂rs√§ljningspris i relation till miltal",
         xaxis = list(title = "Miltal"),
         yaxis = list(title = "F√∂rs√§ljningspris (kr)"))



```


```{r}
ggplot(data, aes(x = Modell√•r)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "white") +
  theme_minimal()
```
###
Jag ville se hur pris och k√∂rstr√§cka varierar mellan olika √•rsmodeller. D√§rf√∂r grupperade jag datan p√• Modell√•r, r√§knade antal bilar, snittpris och snitt-miltal per √•r ‚Äì och sorterade s√• det nyaste kommer √∂verst."


```{r}
data %>%
  group_by(Modell√•r) %>%
  summarise(Antal = n(), MedelPris = mean(F√∂rs√§ljningspris, na.rm = TRUE), MedelMiltal = mean(Miltal, na.rm = TRUE)) %>%
  arrange(desc(Modell√•r))
```
### boxplotar f√∂r att se hur f√∂rs√§ljningspriserna varierar mellan olika faktorer

```{r}
ggplot(data, aes(x = Br√§nsle, y = F√∂rs√§ljningspris)) +
  geom_boxplot(fill = "lightgreen") +
  scale_y_continuous(labels = comma)
```

```{r}
ggplot(data, aes(x = V√§xell√•da, y = F√∂rs√§ljningspris)) +
  geom_boxplot(fill = "skyblue") +
  scale_y_continuous(labels = comma)
```

```{r}
ggplot(data, aes(x = reorder(Region, F√∂rs√§ljningspris, median), y = F√∂rs√§ljningspris)) +
  geom_boxplot(fill = "lightcoral") +
  coord_flip() +
  scale_y_continuous(labels = comma) +
  labs(title = "Prisvariation mellan regioner", x = "Region", y = "Pris") +
  theme_minimal()
```

## üî¢ Modellering: Tr√§ning och test

```{r}
set.seed(123 ) # F√∂r reproducerbarhet, samma uppdelning varje g√•ng koden k√∂rs.
train_index <- createDataPartition(data$F√∂rs√§ljningspris, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ] # testdata p√• osedda data

train_data$logPris <- log(train_data$F√∂rs√§ljningspris)
test_data$logPris <- log(test_data$F√∂rs√§ljningspris) 
#Log-transformerar priset i b√•de tr√§nings- och testdata:

#D√§mpar effekten av extremt h√∂ga priser

#Stabiliserar varians

#G√∂r datan mer normalf√∂rdelad (b√§ttre f√∂r linj√§r regression)
```

## üìà Modell 1 ‚Äì Numeriska variabler

```{r}
options(scipen = 999) # ‚Üê bra kod: Undviker vetenskaplig notation!
model_log <- lm(logPris ~ Miltal + Modell√•r + H√§stkrafter + Motorstorlek, data = train_data)
summary(model_log)
```

```{r}
options(scipen = 999)

pred_log <- predict(model_log, newdata = test_data) # prediktera logaritmerade priser
pred <- exp(pred_log) # exponentiera eller avloggar f√∂r att f√• tillbaka till f√∂rs√§ljningspris i kr
pred[pred < 0] <- 0 # s√§tt negativa v√§rden till 0 bara s√§kerhets skull
postResample(pred, test_data$F√∂rs√§ljningspris) # J√§mf√∂r f√∂ruts√§gelser med verkliga priser p√• testdatan, och r√§knar ut RMSE, R¬≤ och MAE




```

##  Modell 2 ‚Äì Med faktorer

```{r}
options(scipen = 999)

model2 <- lm(logPris ~ Miltal + Modell√•r + H√§stkrafter + Motorstorlek + Br√§nsle + V√§xell√•da, data = train_data)
summary(model2)
```

```{r}
options(scipen = 999)
# S√§kerst√§ll att faktorniv√•erna i test_data matchar train_data
test_data$Br√§nsle <- factor(test_data$Br√§nsle, levels = levels(train_data$Br√§nsle))
test_data$V√§xell√•da <- factor(test_data$V√§xell√•da, levels = levels(train_data$V√§xell√•da))
# Filtrera bort test-observationer med faktorniv√•er som inte finns i tr√§ningen
test_data <- test_data %>%
  filter(!is.na(Br√§nsle), !is.na(V√§xell√•da)) %>%
  filter(Br√§nsle %in% levels(train_data$Br√§nsle), V√§xell√•da %in% levels(train_data$V√§xell√•da))
# Prediktion och back-transformering
pred_log2 <- predict(model2, newdata = test_data)
pred2 <- exp(pred_log2)
pred2[pred2 < 0] <- 0
# Modellutv√§rdering

postResample(pred2, test_data$F√∂rs√§ljningspris)
```

##  Visualisering av modeller

```{r}
ggplot(data.frame(Verkligt = test_data$F√∂rs√§ljningspris, Prediktion = pred2),
       aes(x = Verkligt, y = Prediktion)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  scale_x_continuous(labels = comma) +
  scale_y_continuous(labels = comma)
```

## Diagnostik

```{r}

options(scipen = 999)

shapiro.test(residuals(model2))
bptest(model2)
durbinWatsonTest(model2)
vif(model2)
par(mfrow = c(2, 2))
plot(model2)
par(mfrow = c(1, 1))
```
```{r}
# Ber√§kna residualer
residualer <- residuals(model2)

# Histogram + densitetskurva
ggplot(data.frame(residualer), aes(x = residualer)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "white") +
  geom_density(color = "red", size = 1) +
  labs(title = "Residualernas f√∂rdelning",
       x = "Residualer", y = "Densitet") +
  theme_minimal()

```

```{r}
cooksD <- cooks.distance(model2)

# Ritar graf
plot(cooksD, type = "h", main = "Cook's Distance", ylab = "Cook's Distance")
abline(h = 5 / nrow(train_data), col = "red", lty = 2)

# H√§mtar topp 3 mest inflytelserika observationer
top <- order(cooksD, decreasing = TRUE)[1:3]

# L√§gger till deras index i grafen
text(x = top, y = cooksD[top], labels = top, pos = 2, cex = 0.8, col = "blue")


```
```{r}
# Sammanst√§ll prestanda
resultat_df <- data.frame(
  Modell = c("Modell 1 (endast numeriska)", "Modell 2 (med faktorer)"),
  RMSE = c(postResample(pred, test_data$F√∂rs√§ljningspris)["RMSE"],
           postResample(pred2, test_data$F√∂rs√§ljningspris)["RMSE"]),
  R2 = c(postResample(pred, test_data$F√∂rs√§ljningspris)["Rsquared"],
         postResample(pred2, test_data$F√∂rs√§ljningspris)["Rsquared"]),
  MAE = c(postResample(pred, test_data$F√∂rs√§ljningspris)["MAE"],
          postResample(pred2, test_data$F√∂rs√§ljningspris)["MAE"])
)

# Formatera v√§rden snyggt
resultat_df <- resultat_df %>%
  mutate(across(where(is.numeric), ~round(., 0)))  # Avrunda till hela kr/tal

# Visa som tabell
knitr::kable(resultat_df, caption = "üìã Sammanst√§llning av modellprestanda (testdata)")

```

```{r}
# Visa de tre mest inflytelserika observationerna
data[c(506, 489, 516), ]

```


##  Slutsats

- **Miltal** har en stark negativ p√•verkan.
- **Modell√•r** och **h√§stkrafter** p√•verkar priset positivt.
- **Br√§nsletyp** och **v√§xell√•da** f√∂rb√§ttrar modellens f√∂rklaringsgrad.
- **Modell 2** √§r √∂verl√§gsen Modell 1 enligt RMSE, MAE och R¬≤.



# prediktion av en ny bil:
```{r}
ny_bil <- data.frame(
  Miltal = 6125,
  Modell√•r = 2018,
  H√§stkrafter = 153,
  Motorstorlek = 1969,
  Br√§nsle = factor("Bensin", levels = levels(train_data$Br√§nsle)),
  V√§xell√•da = factor("Manuell", levels = levels(train_data$V√§xell√•da))
)

log_pred <- predict(model2, newdata = ny_bil)
pris_pred <- exp(log_pred)
pris_pred
# Det verkliga priest √§r 179 900 kr
```
# F√∂r en annan bil, en Volvo V40 T3 fr√•n 2018 med manuell v√§xell√•da, 153 hk och 6 125 mil, f√∂rutsade modellen ett pris p√• 158 933 kr. Det faktiska annonspriset var 179 900 kr. Skillnaden kan bero p√• extrautrustning eller priss√§ttning ut√∂ver grundspecifikationerna. Trots detta l√•g f√∂ruts√§gelsen n√§ra det faktiska intervallet, vilket tyder p√• att modellen har praktisk relevans

